# -*- coding: utf-8 -*-
"""Copy of Copy of Data Project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r2dPFJ27WwFkkEZZGGKdLUHwwJPVpWOw

#Project - Data Project

This project is designed to be self-driven, helping you to incorporate a variety of techiniques to help you analyze a dataset of your choice.

You’re going to be picking a dataset, examining and visualizing it, then using some of the ML methods we’ve learned this week to make some predictions about it!

This is something that can take months if not years - do your best!

For an example of what a finished data project could look like, you can download and view the following document: [Honors Thesis](https://scholarsarchive.byu.edu/studentpub_uht/132/). Please note that this is an example of a data project that took several months to accomplish. Yours will be a much smaller version of this, but should still be something that you are proud of when you finish it.

##Steps
----

1. Choose a dataset from the [UCI ML library](https://archive.ics.uci.edu/ml/datasets.php).
  - Make sure the dataset is:
    - relatively clean (Missing Values? should say 'no')
    - designed for regression or classification (Associated Tasks: shoudl say 'classification' or 'regression')
2. Download the dataset
  - At the top of the page for your given dataset, there will be a line that says, Download: Data folder, Data Set Description
  - in the data folder, you should find a `____.data` and `____.names`
  - the `.names` file is the data description. You will need this to understand your data
3. Read in your dataset to google Colab
 - the `.data` file is the actual data file. If you download it and try to open it (in Notepad), you will see many rows of comma-separated data. Use `pd.read_csv()` to read in and use your data file
    - ask a TA for help to do this if you are confused 

Helpful code (copy this into a separate block):
```
from google.colab import drive
drive.mount('/content/drive')

file = pd.read_csv("/content/drive/My Drive/<filename>.csv")
```


4. Make sure your dataset is formatted correctly as a Pandas dataframe, and that you have read and understood its documentation
  - remember, the `.names` file is the documentation for your datset
  
  - To format your data and make it easier to use, remember to separate out the data portion and target column of your dataset in the following way:

```
data = file.drop(labels=["target_column_name"], axis=1)
target = file["target_columns_name"]
```
Feel free to change the variable names to something that you like.

5. Write some questions that you want to answer about your data. Some of these should be answerable by visualizing the data and looking for trends, while others should be questions answerable only through ML techniques.

6. Use your Data Visualization skills to create some charts that explore your data. 
  - Make sure to use specific title, axis labels, colors, etc to communicate clearly what you are looking at in each chart.
  - Write at least one sentence about each visualization - why did you make it, what do you see, and what does it tell you about the data as a whole

7. Choose at least two ML techniques that we have learned about this week, and use them to predict a value or values from your dataset. This step should help answer at least one fo the questions you asked/formed in step 5.
8. Show the results of your predictions
  - Use visualizations if possible. 
  - Make sure to explain what the results mean, and what they tell you about the data
  - why do your results matter?
9. Write at least one paragraph about the ethical implications of your project. If there are no potential issues, explain why. If there are potential issues, explain what they are and what steps could or should be taken in the future to prevent those problems
10. Write a conclusion explaining and summarizing what you did in this project.
"""

#The main goal here is to predict the rating of cereals based on how much suger is in them. We try to find the relationship between the two factors.

#imports
import sklearn
from sklearn import datasets
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import image
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier
from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier
from sklearn import metrics
from google.colab import drive
from sklearn.linear_model import LinearRegression
drive.mount('/content/drive') #mount your google drive to colaboratory (makes the drive available for use)

cereal = pd.read_csv("/content/drive/My Drive/cereal.csv") #accesses the csv file of the cereal data (from google drive) and creates a cereal dataframe out of it
target = cereal["rating"] #sets the target to cereal rating (thing we are trying to find)(dependent variable); the ratings column is stored here
cereal = cereal.drop(labels=["rating"], axis=1) #gets rid of the ratings column from the cereal dataframe (because we already have it stored in the 'target' variable and just need it in there)
cereal.head()
print(cereal) #prints sample of data from the cereal dataframe

X = cereal['sugars'] #set X to sugars (independent variable)
X = X.to_frame() #turns X into a dataframe
#VISUAL
#     sugars
#0        6
#1        8
#2        5
#3        0
#4        8
#...     ...
#72       3
#73      12
#74       3
#75       3
#76       8
y = target #sets the target (rating) to y

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42) #splits the data into train and test; test size is 0.2 of the data; random_state sets the seed (the starting point in random number generation)
#training data - allows the computer to get a feel and understanding for the data
#testing data - used for evaluation on the performance and progress of the trained algorithm

model1 = LinearRegression() #creates the model (in this case it is a Linear Regression model)
model1.fit(X_train, y_train)  #trains (teaches) the model
pred1 = model1.predict(X_test) #makes predictions on what the y_test values (ratings) would be according to the x_test values (sugars) after being taught with the training data; we dont put y in there because we would essenitally be giving the computer the answer

plt.figure(figsize=(10, 10)) #sets the size of the chart
plt.scatter(X_test, pred1) #creates scatterplot with X_test(sugars) as the X axis and pred1(ratings) as the Y axis
plt.axis('tight') #sets limits of x & y; 'tight' tightens the bounds around the current plot
plt.xlabel('sugars') #labels the x axis to sugars
plt.ylabel('rating') #labels the y axis to rating
plt.title("How high is the rating of each cereal when looking at the amount of sugars?") #sets title to objective
plt.legend(["Cereal"]) #shows a legend for the graph (if necessary)
plt.tight_layout() #cleans up any padding between subplots (if any) for a cleaner look (seperates the subplots if they are too squished together)


#THINK OF THE PROCESS LIKE THIS:
#A math teacher gives a student sample problems with answers (training data), then gives the student practice problems in which the answer is not provided and the student must find it themselves (test data), applying the knowledge he/she picked up from the sample problems. The teacher would grade the students performance using the answer key (y_test)

#optional
img = image.imread("/content/drive/My Drive/cereal.jpeg") #accesess a photo from google drive
plt.imshow(img) #and shows it
plt.show()

"""# © 2022 The Coding School. All rights reserved"""